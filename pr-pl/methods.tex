\section{Combinatorial Methods}

\subsection{Combinatorial Nullstellensatz}

	The reader is likely familiar with the following famous theorem.

	\begin{ftheo}[Hilbert's Nullstellensatz]
		Let $\F$ be an algebraically closed field and $f,g_1,\ldots,g_m$ be elements of the ring $\F[x_1,\ldots,x_n]$ of polynomials such that $f$ vanishes on all common zeroes of the $(g_i)$. Then, there is an integer $k$ and polynomials $h_1,\ldots,h_m$ in $\F[x_1,\ldots,x_n]$ such that
		\[ f^k = \sum_{i=1}^{m} g_i h_i. \]
	\end{ftheo}

	Before we get to the main result of this section which is essentially an interesting form of the above when the $g_i$ take a specific form, we give a lemma related to the size of a `cube' required to evaluate a polynomial at to determine if it is the $0$ polynomial.

	\begin{lemma}
		\label{lem: comb null lem}
		Let $P = P(x_1,\ldots,x_n)$ be a polynomial over a(n arbitrary) field $\F$. Suppose that for each $i$, $S_i \subseteq \F$ with $|S_i| > \deg_i(P)$. If $P(s_1,\ldots,s_n) = 0$ for all choices of $s_i \in S_i$ for each $i$, then $P$ is identically $0$. 
	\end{lemma}
	\begin{proof}
		We prove this by induction on $n$. When $n=1$, this is direct as it merely states that a polynomial of degree at most $t$ has at most $t$ zeroes. Suppose that the statement is true for $n-1$. Let $t_i = \deg_i(P)$ for each $i$. Write $P$ as a sum
		\[ P = \sum_{i=0}^{t_i} x_n^i P_i(x_1,\ldots,x_{n-1}), \]
		where each $P_i$ is a polynomial with $\deg_j$ bounded above by $t_j$. Observe that for any fixed tuple $(x_1,\ldots,x_{n-1}) \in S_1 \times \cdots \times S_{n-1}$, the polynomial obtained from $P$ by substituting the values of $x_1,\ldots,x_{n-1}$ vanishes on $S_n$, and thus by the $n=1$ case, is identically zero. Therefore, each $P_i$ vanishes on $S_1 \times \cdots \times S_{n-1}$. Applying the inductive hypothesis, each $P_i$ is thus identically $0$, yielding that $P$ is identically $0$ and completing the proof.
	\end{proof}

	Later in \Cref{thm: cube-vanishing}, we give a much stronger version of this

	\begin{ftheo}[Combinatorial Nullstellensatz]
		\label{thm: comb null}
		Let $\F$ be an algebraically closed field and $S_1,\ldots,S_n \subseteq \F$. Define
		\[ g_i(x_i) = \prod_{s_i \in S_i} (x_i - s_i) \]
		for each $i$. Let $f \in \F[x_1,\ldots,x_n]$ vanish on all common zeroes of the $(g_i)$, that is, $f(s_1,\ldots,s_n) = 0$ if $s_i \in S_i$ for each $i$. Then, there are polynomials $h_1,\ldots,h_n$ in $\F[x_1,\ldots,x_n]$ such that
		\[ f = \sum_{i=1}^{m} g_i h_i. \]
		and $\deg(h_i) \le \deg(f) - \deg(g_i)$ for each $i$.\\
		Moreover, if $f,g_1,\ldots,g_n \in R[x_1,\ldots,x_n]$ for some subring $R$ of $\F$, then there are polynomials $h_i \in R[x_1,\ldots,x_n]$ satisfying the above.
	\end{ftheo}
	\begin{proof}
		Let $t_i = |S_i| - 1$ for each $i$. For each $i$, write $g(x_i) = x_i^{t_i+1} - g_0(x_i)$ -- note that $g_0$ is a polynomial of degree at most $t_i$. For each $x_i \in S_i$, we then have
		\[ x_i^{t_i + 1} = g_0(x_i). \]
		Now, take the polynomial $f$ and subtract polynomials of the form $h_i g_i$, each of which replaces the higher degree terms of $x_i$ (terms with $x_i^{r}$ for $r > t_i$) with a lower degree one using the above equation, to get a polynomial $f_0$. Observe that this polynomial $f_0$ vanishes on $S_1 \times \cdots \times S_n$, and $\deg_i(f_0) \le t_i$ for each $i$. We can then use \Cref{lem: comb null lem} to conclude that $f_0$ is identically zero, and thus that $f$ is equal to $\sum_i h_i g_i$, completing the proof.
	\end{proof}

	The simple proof above betrays the surprising usefulness of this result.

	\begin{fcor}
		\label{thm: cube-vanishing}
		Let $P = P(x_1,\ldots,x_n)$ be a polynomial over a(n arbitrary) field $\F$. Let $\deg(f) = \sum_i t_i$, and let there exist a $x_1^{t_1} x_2^{t_2} \cdots x_n^{t_n}$ term in the polynomial with non-zero coefficient. Suppose that for each $i$, $S_i \subseteq \F$ with $|S_i| > t_i$. If $P(s_1,\ldots,s_n) = 0$ for all choices of $s_i \in S_i$ for each $i$, then $P$ is identically $0$. 
	\end{fcor}
	\begin{proof}
		Let us assume that $|S_i| = t_i + 1$ for each $i$.\\
		Suppose that the claim does not hold and let $g_i(x_i) = \prod_{s_i \in S_i} (x_i - s_i)$ for each $i$. \nameref{thm: comb null} then implies that
		\[ P = \sum_i h_i g_i \]
		for polynomials $h_i$ of degree at most $\deg(f) - \deg(g_i)$. Now, any monomial of degree $\deg(f)$ must come from one of the $h_i g_i$. However, any term in these polynomials are divisible by $x_i^{|S_i|} = x_i^{t_i + 1}$, which implies that there is no $x_i^{t_i}$ term in $P$, yielding a contradiction and completing the proof.
	\end{proof}

	Now, let us give some examples of the use of combinatorial nullstellensatz.
	
	\begin{prop}
		Let $A = (a_{ij})$ be a $n\times n$ matrix over a field $F$ that has non-zero permanent. Then, for any $b = (b_1,\ldots,b_n) \in F^n$ and family $S_1,\ldots,S_n \subseteq F$ of size at least $2$, there exists some $x \in S_1 \times \cdots \times S_n$ such that $Ax$ differs from $b$ at every coordinate. 
	\end{prop}
	\begin{proof}
		The polynomial
		\[ \prod_{i=1}^n \left(\sum_{j=1}^n a_{ij} x_j - b_j \right) \]
		is of degree $n$ and the coefficient of $\prod x_i$ in it is the permanent of $A$, which is non-zero. The desideratum follows on using \Cref{thm: cube-vanishing}.
	\end{proof}
	
	Given an undirected graph $G = ([n],E)$, define the graph polynomial
	\[ f_G(x_1,\ldots,x_n) = \prod_{\substack{ij \in E \\ i < j}} (x_i - x_j). \]

	\begin{prop}
		A graph $G = ([n],E)$ is not $k$-colorable if and only if its graph polynomial lies in the ideal generated by $P_i(x) = x_i^k - 1$ (for $1 \le i \le n$).
	\end{prop}
	\begin{proof}
		Number the $k$th roots of unity as $z_1,\ldots,z_k$.\\
		If $f_G$ is in the mentioned ideal but $G$ is $k$-colorable, then it does not vanish at some point where each $x_i$ is a $k$th root of unity. However, this is a common zero of all the $P_i$, which contradicts the fact that it is in the given ideal.\\
		On the other hand, if $G$ is not $k$-colorable, then it vanishes at all common zeros of the $P_i$. \Cref{thm: comb null} then implies the required.
	\end{proof}

	\begin{prop}
		Consider the vertices $\{0,1\}^n$ of the hypercube in $\R^n$. Let $\{H_i\}_{i=1}^m$ be a set of hyperplanes that cover every vertex except one. Then, $m \ge n$.
	\end{prop}
	\begin{proof}
		Assume that the uncovered vertex is $\textbf{0}$. Let the $m$ hyperplanes be given be $\langle a_i, x \rangle + b_i = 0$. Observe that $b_i \ne 0$ for all $i$. Suppose instead that $m < n$. Consider the polynomial
		\[ P(x_1,\ldots,x_n) = \prod_{i=1}^m b_i \prod_{i=1}^n (1-x_i) - \prod_{i=1}^m (\langle a_i, x\rangle + b_i) \]
		over $\F_2$.\\
		Because $m < n$, the term in $P$ of maximal degree is $(-1)^n \prod_{i=1}^n x_i$ and has non-zero coefficient. By \Cref{thm: cube-vanishing}, there exist some $\utilde{z} = z_1,\ldots,z_n \in \F_2^n$ such that $P(\utilde{z}) \ne 0$. However, if $\utilde{z} = 0$, the first term cancels out with the second term. If $\utilde{z} \ne 0$, some $\langle a_i,x\rangle + b_i$ vanishes at $\utilde{z}$, and $z_i = 1$ for some $i$ so the first term vanishes as well. This is a contradiction, and therefore $m \ge n$.
	\end{proof}

	\begin{prop}
		Let $p$ be a prime and $P_i(x_1,\ldots,x_n)$ (for $1\le i\le m$) be polynomials in the ring $\F_p[x_1,\ldots,x_n]$. If $n > \sum_i \deg(P_i)$ and the $P_i$ have a common zero, they have another common zero.
	\end{prop}
	\begin{proof}
		Let $(c_1,\ldots,c_n)$ be a common zero of the $P_i$, and suppose that no other common zero exists. Consider the polynomial
		\[ f(x_1,\ldots,x_n) = \prod_{i=1}^m \left( 1 - P_i(x_1,\ldots,x_m)^{p-1} \right) - \prod_{i=1}^n \left( 1 - (x_i - c_i)^{p-1} \right). \]
		Observe that $f$ vanishes everywhere! However, the term of maximal degree is $\prod_{i=1}^n x_i^{p-1}$ and has non-zero coefficient. This leads to a contradiction on using \Cref{thm: cube-vanishing}, proving the required.
	\end{proof}



\subsection{The Polynomial Method}

	The issue with combinatorial nullstellensatz is that we need to carefully craft a polynomial of low degree that satisfies the constraints we desire. As a result, it often also gives extremely tight bounds.\\
	However, this crafting is not always easy. Enter the polynomial method. Instead of choosing a specific polynomial, we choose a polynomial of lowest degree that vanishes at the desired points. While this may not give as tight a bound as combinatorial nullstellensatz, it often gives good asymptotic bounds.

	The primary premise of the polynomial method is the following.

	\begin{lemma}
		\label{poly method}
		Suppose $S \subseteq \F^n$ is a finite set and $|S| \le \binom{n+d}{n}$. Then, there exists a non-trivial polynomial $f \in \F_q[X_1,\ldots,X_n]$ of degree at most $d$ such that $S \subseteq Z(f)$. In particular, given a finite set $S$, there is a polynomial of degree at most $n|S|^{1/n}$ such that $S \subseteq Z(f)$.
	\end{lemma}

	\begin{lemma}
		\label{poly method: line containment}
		Suppose $f \in \F[X_1,\ldots,X_n]$ is a polynomial of degree at most $d$. Then, for any line $\ell$, $|\ell \cap Z(f)| \le d$ or $\ell \subseteq Z(f)$.
	\end{lemma}

	Both the above are reasonably easy to prove.\\
	Further observe that neither of the two above lemmas assert that $\F$ is finite.

	\subsubsection{The finite Kakeya problem}

		Let $q$ be a prime power. A set $K \subseteq \F_q^n$ is said to be a \emph{Kakeya set} if for every direction $v$, there is a line $\ell_v$ parallel to $v$ that is contained in $K$. Does there exist some constant $c_n$ (independent of $q$) such that $|K| \ge c_n q^n$?

		\begin{prop}
			Given $q,n$, any Kakeya set $K \subseteq \F_q^n$ is of size at least $(q/2n)^n$.
		\end{prop}

		\begin{proof}
			Let $K$ be a Kakeya set of size $cq^n$. Let $f$ be a polynomial of minimal degree that vanishes over $K$. By \Cref{poly method}, $\deg(f) \le nqc^{1/n}$. Let us show that $nc^{1/n} \le 1/2$. \\
			Suppose otherwise.
			Fix some non-zero $v \in \F_q^n$. By the definition of a Kakeya set, there exists $a \in \F_q^n$ such that $g(t) = f(a_1 + tv_1, \ldots, a_n + tv_n) = 0$ for all $t \in \F_q$. $g$ is a polynomial of degree at most $q/2$ that vanishes at $q$ points of the line. Therefore, $g$ is identically zero. Letting $f_H$ be the homogeneous part of highest degree terms of $f$, we have that the coefficient $f_H(v)$ of $t^k$ obtained from $f_H$ is zero. Since $v$ is arbitrary, $f_H$ must vanish at all $v$, so $f_H$ is identically zero. However, this is a contradiction, completing the proof.
		\end{proof}

		Interestingly, before this, the best known bound was just around $q^{(n+2)/2}$ with very minor improvements over time.\\
		A slightly more sophisticated argument may be performed (with the same basic template), taking into account the multiplicities of zeros, to get a bound of $q^n/2^n$ on the Kakeya set. The smallest known Kakeya set is of size $q^n/2^{n-1} + O(q^{n-1})$, so the problem is basically resolved.

	\subsubsection{The joints problem}

		Let $\mathcal{L}$ be a collection of lines in $\R^3$. A \emph{joint} $j$ is a point such that three non-coplanar lines of $\mathcal{L}$ pass through $j$. Given $|\mathcal{L}| = L$, what is the maximum number of joints the lines can determine? \\

		Refer to this maximum quantity as $j(L)$.\\
		Let $\mathcal{L}$ be a set of lines that attains the $j(L)$ bound, and let $f$ be a non-trivial polynomial of minimal degree that vanishes on the set $J$ of joints. Then, $\deg(f) \le 3j(L)^{1/3}$.\\

		For every line $\ell$, either $|\ell \cap Z(f)| \le 3j(L)^{1/3}$ or $\ell \cap Z(f)$.\\
		If every line $\ell$ contains more than $3j(L)^{1/3}$, then every $\ell$ is contained in $Z(f)$. Therefore, $f$ is identically zero when restricted to any of the lines. Since a joint has three non-coplanar lines through it, we have $\nabla f (p) = 0$ at any joint $p$. However, in this case,
		\[ \dpd{f}{x} (p) = \dpd{f}{y} (p) = \dpd{f}{z} (p) = 0. \]
		So, each of the partial derivatives of $f$ is a polynomial that vanishes at every joint. Unless all the partial derivatives are identically zero, this contradicts the minimality of $f$! But in this case, $f$ is identically zero as well, once again leading to a contradiction.\\

		Therefore, there always exists a line $\ell$ with at most $3j(L)^{1/3}$ lines. In this case,
		\[ j(L) \le 3j(L)^{1/3} + j(L-1) \le \sum_{k=1}^{L} 3j(k)^{1/3} \le 3Lj(L)^{1/3}. \]
		Therefore,
		\[ j(L) \le 3^{3/2} L^{3/2}. \]